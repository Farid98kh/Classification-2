---
title: "Denetimli Ä°statistiksel Ã–ÄŸrenme Finali"
author: "Farid KHORSHIDI"
date: "2023-11-30"
output:
  pdf_document:
    latex_engine: xelatex
    keep_tex: true
    number_sections: true
    toc: true
    toc_depth: 3
    fig_caption: yes
    df_print: kable
    highlight: tango
header-includes:
  - "\\usepackage{fontspec}"
  - "\\setmainfont{Times New Roman}"
  - "\\renewcommand{\\normalsize}{\\fontsize{10}{12}\\selectfont}" 
  - "\\usepackage{hyperref}"
  - "\\hypersetup{pdfpagelayout=SinglePage}"  
  - "\\hypersetup{pdfstartview=FitH}"  
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE,warning = FALSE, message = FALSE, fig.align = 'center', out.width = "50%", out.height = "60%")

```


```{r KÃ¼tÃ¼phaneler, include=FALSE}
# KÃ¼tÃ¼phaneler
library(readr)
library(caret)
library(tidyverse)
library(magrittr)
library(olsrr)
library(car)
library(corrplot)
library(ISLR)
library(Hmisc)
library(caret)
library(performance)
library(ROCR)
library(dplyr)
library(ModelMetrics)
library(lmtest)
library(moments)
library(bestNormalize) # normalization 
library(MASS)
library(psych) 
library(mvnTest) # perform multivariate normality test
library(tree) # perform regression and decision tree
library(randomForest) # perform random forest
library(rpart)       # performing regression trees
library(rpart.plot)  # plotting regression trees
library(ipred)       # bagging
library(klaR)
library(e1071)
library(gridExtra)
library(ggalt)
#install.packages("ROCR")
library(ROCR)
library(MVN)
library(ggplot2)
library(mice)
library(RColorBrewer)
```

# Veri Seti
**Bu Veri Setinde Makine Ã–ÄŸrenmesi modellemeleriyle Deniz KulaÄŸÄ±nÄ±n Ã¼zerindeki `Rings` veya Halka mikatarÄ±nÄ±n farkllÄ± gÃ¶zlemlerde Tahmin edilmesi amaÃ§lamaktadÄ±r. Halka sayÄ±sÄ±nÄ±n ilgilenilen Deniz KulaÄŸÄ± gÃ¶zleminde 1.5 katÄ± onun yaÅŸÄ±nÄ± gÃ¶sterdiÄŸini belirtmek isterim, o yÃ¼zden bu Ã§alÄ±ÅŸma YaÅŸ(Age) Tahminlemesi olarak incelenecektir **


```{r echo=FALSE}
abalone_veriseti <- read_csv("G:/Yuksek Lisans/denetimli istatistiksel ogrenme/2. kez/final/abalone_veriseti.data", 
                             col_names = FALSE)
variable_names <- c("Sex",	"Length",	"Diameter",	"Height",	"Whole.weight",	"Shucked.weight",	"Viscera.weight",	"Shell.weight",	"Rings")
colnames(abalone_veriseti) <- variable_names

df <- abalone_veriseti
df$Sex <- as.factor(df$Sex)
df <- as.data.frame(df)
head(df)
```



```{r}
for(i in 1:9){
  print(paste(names(df[i]),sep = "", "----class:" ,class(df[,i])))
}
```

```{r echo=FALSE}
dim(df)
```
*4177 tane farkli gÃ¶zlemden toplanmiÅŸ veriler incelenecektir.*

# A - REGRESYON

**DeÄŸiÅŸkenler** 

1. Cinsiyet: nominal / Kategorik / E, K ve B (bebek)
2. Uzunluk: sÃ¼rekli / mm / En uzun kabuk Ã¶lÃ§Ã¼mÃ¼
3. Ã‡ap: sÃ¼rekli / mm / uzunluÄŸa dik
4. YÃ¼kseklik: sÃ¼rekli / mm / kabuklu et ile
5. Tam aÄŸÄ±rlÄ±k: sÃ¼rekli / gram / bÃ¼tÃ¼n denizkulaÄŸÄ±nÄ±n aÄŸÄ±rlÄ±ÄŸÄ±
6. SÄ±kÄ±lmÄ±ÅŸ aÄŸÄ±rlÄ±k: sÃ¼rekli / gram / et aÄŸÄ±rlÄ±ÄŸÄ±
7. Ä°Ã§ organ aÄŸÄ±rlÄ±ÄŸÄ±: sÃ¼rekli / gram / baÄŸÄ±rsak aÄŸÄ±rlÄ±ÄŸÄ± (kanama sonrasÄ±)
8. Kabuk aÄŸÄ±rlÄ±ÄŸÄ±: sÃ¼rekli / gram / kurutulduktan sonra
9. Halkalar: tamsayÄ± / -- / +1,5 yÄ±l cinsinden yaÅŸÄ± verir


Daha analize baÅŸlamadan `Length`le `Height` veya `Whole.weight` le `Shucked.weight` gibi deÄŸiÅŸkenlerin aÃ§Ä±klamasÄ±nda gÃ¶sterildiÄŸi gibi aynÄ± Ã¶lÃ§Ã¼mde ve birbirini etkileyeceÄŸini dÃ¼ÅŸÃ¼ndÃ¼ÄŸÃ¼mÃ¼z konseptde olduklarÄ± iÃ§in birbiriyle gÃ¼Ã§lÃ¼ iliÅŸkide olduklarÄ± ve Ã§oklu baÄŸlantÄ± problemiyle modellemede karÅŸÄ±laÅŸa bileceÄŸimizi Ã¶ngÃ¶rebiliriz.
```{r include=FALSE}
md.pattern(Carseats)
sum(is.na(df))
```


```{r echo=FALSE}
smpl_size <- floor(0.7 * nrow(df))
set.seed(191)
train_id <- sample(1:nrow(df), size = smpl_size)
train <- df[train_id,]
test <- df[-train_id,]
```

## TanÄ±mlayÄ±cÄ± Ä°statistikler
### Ã–zet Ä°statistikler
```{r echo=FALSE}
summary(train)
```
### SayÄ±sal DeÄŸiÅŸkenlerin Standart SapmalarÄ±
```{r echo=FALSE}
apply(train[,2:9],2, sd)
```
ilk bakÄ±ÅŸta bÃ¼tÃ¼n sayÄ±sal deÄŸiÅŸkenlerin Ã¶zellikle hedef deÄŸiÅŸken yani Rings, aralÄ±k ve rangelerine nispeten mean ile medianlarÄ± bir birine Ã§ok yakÄ±n olduklarÄ±nÄ± gÃ¶zlemliyoruz.
Ortalamadan 2 Standart Sapma uzaklÄ±ÄŸÄ±nda yÃ¼zde 95 Ã¼zeri verilerimizin olduÄŸunu bilerek; Length, Height, Shucked.weight,  Viscera.weight, Shell.weight, Rings deÄŸiÅŸkeninin de minimum ve maksimum deÄŸerlerini her ikisi veya biri bu aralÄ±ÄŸÄ±n Ã§ok dÄ±ÅŸÄ±nda kaldÄ±ÄŸÄ±ndan ilerideki analizlerde bunlarda *`Outlier`* gÃ¶rebiliriz.

### SayÄ±sal DeÄŸiÅŸkenlerin Ã‡arpÄ±klÄ±klarÄ±
```{r echo=FALSE}
apply(train[,2:9],2, skewness)
```
1. *Length* : aralÄ±ÄŸÄ± 0.75 ve sola Ã§arpÄ±ktÄ±r.
2. *Diameter* : aralÄ±ÄŸÄ± 0.6 ve sola Ã§arpÄ±ktÄ±r.
3. *Height* : aralÄ±ÄŸÄ± 1.13 ve saÄŸa Ã§arpÄ±ktÄ±r.
4. *Whole.weight* : aralÄ±ÄŸÄ± 2.8 ve Ã§ok az saÄŸa Ã§arpÄ±ktÄ±r.
5. *Shucked.weight* : aralÄ±ÄŸÄ± 1.4 ve saÄŸa Ã§arpÄ±ktÄ±r.
6. *Viscera.weight* : aralÄ±ÄŸÄ± 0.76 ve saÄŸa Ã§arpÄ±ktÄ±r.
7. *Shell.weight* : aralÄ±ÄŸÄ± 1 ve saÄŸa Ã§arpÄ±ktÄ±r.
8. *Rings* : aralÄ±ÄŸÄ± 28 ve saÄŸa Ã§arpÄ±ktÄ±r.
Toplamda deÄŸiÅŸkenler Ring dÄ±ÅŸÄ±nda yakÄ±n aralÄ±klar yanlÄ±z farklÄ± birimlerden(Uzunluk, aÄŸÄ±rlÄ±k ve yaÅŸ) oluÅŸmaktadÄ±rlar.

Ring veya hedef deÄŸiÅŸkeni DeÄŸiÅŸkeni integer ve 28 dÃ¼zeyden oluÅŸtuÄŸu ve Ã¶zet istatistiklerde kategorik davrandÄ±ÄŸÄ± iÃ§in aÃ§Ä±kca kategorik bir deÄŸiÅŸken olarak incelenebileceÄŸi ortadadÄ±r. yani sÄ±nÄ±flandÄ±rma problemi olarak ele alÄ±nacaÄŸÄ± daha uygun bir analiz olur.
```{r echo=FALSE}
nlevels(as.factor(df$Rings))
```
### SayÄ±sal deÄŸiÅŸkenlerin Boxplot grafikleri
```{r echo=FALSE, out.height="60%",out.width="60%"}
my_pallete <- brewer.pal(n=8, name = "Pastel2")
par(mfrow= c(2,4))
for(i in 2:9){
  
  boxplot(train[,i], main = names(train)[i], col = my_pallete[i])
}
```
\textcolor{blue}{SayÄ±sal deÄŸiÅŸkenlerin Boxplot grafiklerinden median ve quartile lar Ã§izgisine bakarak da Ã¶zet istatistiklerdeki ifadeleri tsepit edebiliriz, Ã¶rneÄŸin deÄŸiÅŸkenlerin normal veya normale yakÄ±n daÄŸÄ±ldÄ±klarÄ± ve daha Ã¶nce de sÃ¶ylediÄŸimiz bazÄ± deÄŸiÅŸkenlerde uÃ§ deÄŸer barÄ±ndÄ±rdÄ±klarÄ±na iliÅŸkin yorumda bulunabiliriz.}


### Kategorik deÄŸiÅŸkenlerin Boxplot grafikleri
```{r echo=FALSE, out.height="60%",out.width="60%"}
indexes = sapply(train, is.factor)
indexes["Rings"] = TRUE
train[,indexes]%>%
  gather(-Rings, key = "var", value = "value") %>% 
  ggplot(aes(x = value, y = Rings, color = value)) +
  geom_boxplot() +
  facet_wrap(~ var, scales = "free")+
  theme(axis.text.x = element_text(angle = 30, hjust = 0.85),legend.position="none")
```
- \textcolor{blue}{Kategorik deÄŸiÅŸken olarak Cinsiyet etkisini BaÄŸÄ±mlÄ± deÄŸiÅŸken Ã¼zerinde daha saÄŸlÄ±klÄ± analiz edebilmek iÃ§in boxplotÄ±na bakÄ±ldÄ±ÄŸÄ±nda `Sex` deÄŸiÅŸkeninin seviyelerinin hepsi Rings deÄŸiÅŸkeninin normal daÄŸÄ±ldÄ±ÄŸÄ±nÄ± ve mean ile medianÄ±nÄ±n hepsinde 7.5 ile 10 arasÄ±nda olduÄŸunu gÃ¶sterirken, sadece Infant seviyesi diÄŸerleri 10 iken yaklaÅŸÄ±k 8 olmuÅŸtur.}

- \textcolor{blue}{veri yapÄ±sÄ±na gÃ¶re herhangi bir seviye birleÅŸtirme anlamsÄ±z ve bilgi kaybÄ±dÄ±r, modelde buna kesin karar verilecektir.}

### Matris Plot ve Korelasyon Analizi
```{r echo=FALSE, message=FALSE, warning=FALSE , out.height="90%",out.width="90%"}
par(mfrow=c(1,1))
cor.data <- cor(train[2:9])
cor.data
corrplot.mixed(cor.data, upper = "pie", tl.cex=0.58)
pairs.panels(train[2:9], main="Scatter Plotlar ve histogramlar")
```

**Plotlar ve Korelasyon Matrisi Ä°ncelendiÄŸinde**
- Daha Ã¶nce de Ã¶ngÃ¶rdÃ¼ÄŸÃ¼mÃ¼z Korelasyon matrisinden deÄŸiÅŸkenler hepsinin arasÄ±nda Ã§ok fazla gÃ¼Ã§lÃ¼ ve extra kuvvetli pozitif iliÅŸki olduÄŸunu ve dolayÄ±sÄ±yla Ã§oklu baÄŸlantÄ±ya **duyarlÄ±** DoÄŸrusal regresyon ve Lojistik regresyon modellemelerinde *\textcolor{red}{olaÄŸan Ã¼stÃ¼ multicollinearity}* ve yanlÄ±lÄ±k problemiyle karÅŸÄ±laÅŸacaÄŸÄ±mÄ±z anlaÅŸÄ±lmaktadÄ±r.
- baÄŸÄ±msÄ±z deÄŸiÅŸkenlerin arasÄ±ndaki iliÅŸkinin onlarÄ±n baÄŸÄ±mlÄ± deÄŸiÅŸkenle aralarÄ±ndak iliÅŸkiden fazla olmasÄ± dikkat Ã§ekiyor.
- BaÄŸÄ±mlÄ± deÄŸiÅŸkenle en Ã§ok iliÅŸkisi olan deÄŸiÅŸken `Shell.weight` dir bu da karar aÄŸaÃ§larÄ± gibi algoritmalarda ilerleyen analizlerde en etkin olacaÄŸÄ± kÃ¶k dÃ¼ÄŸÃ¼m olabilmesi anlamÄ±na gelir.
- Buradan ileride ilgili model iÃ§in gÃ¼Ã§lÃ¼ iliÅŸkili deÄŸiÅŸkenlerin Ã‡oklu BaÄŸlantÄ± kurduklarÄ± iÃ§in bazÄ±sÄ±nÄ± Ã§Ä±karmak veya **Temel BileÅŸenler Analizi** ile boyut indirgemesi yapÄ±labileceÄŸi yorumunu Ã§Ä±kardÄ±k.

**Ä°statistiksel Hipotez Testleri veya VarsayÄ±m KontrolÃ¼ %95 gÃ¼venle bu iki yol izlenerek tespit edilir**  
*EÄŸer p_value > 0.05 null hipotez reddedilemez*  
*EÄŸer p_value < 0.05 null hipotez reddedilir*

## BaÄŸÄ±mlÄ± DeÄŸiÅŸkenin Normallik Testi
*\textcolor{red}{Ho : Rings deÄŸiÅŸkeni normal daÄŸÄ±lmÄ±ÅŸtÄ±r.}*  
*\textcolor{red}{Ha : Rings deÄŸiÅŸkeni normal daÄŸÄ±lmamaktadÄ±r.}*

- *Uygun Durum* : p_value > 0.05
```{r echo=FALSE}
shapiro.test(train$Rings)
```

```{r echo=FALSE}
outliers <- which(abs(scale(log(df$Rings)))>3)
shapiro.test(scale(log(df$Rings[-outliers])))
```
BaÄŸÄ±mlÄ± deÄŸiÅŸken 0.95 gÃ¼venle normal daÄŸÄ±lmamaktadÄ±r.  
BaÄŸÄ±mlÄ± deÄŸiÅŸkenin standartlaÅŸtÄ±rÄ±lmÄ±ÅŸ logaritmik dÃ¶nÃ¼ÅŸÃ¼mÃ¼nden aykÄ±rÄ± deÄŸerler Ã§Ä±karÄ±ldÄ±ktan sonra da normallik saÄŸlanamamÄ±ÅŸtÄ±r.
BÃ¶ylelikle doÄŸrusal regresyonda artÄ±klarÄ±n normal daÄŸÄ±ldÄ±ÄŸÄ± varsayÄ±mÄ±nÄ± engelleyen durum vardÄ±r.


## 1 - DoÄŸrusal Regresyon

```{r echo=FALSE}
LR <- lm(log(Rings) ~ Sex + Length + Diameter + Height + Whole.weight + Shucked.weight + Viscera.weight + Shell.weight,data = train)
summary(LR)
```
*\textcolor{red}{Ä°lk baÅŸta Full Modeli kurdum ve sadece SexM deÄŸiÅŸkeni anlamsÄ±z Ã§Ä±ktÄ±}*  
Ã§oklu baÄŸlantÄ± problemi ni kaldÄ±rmak iÃ§in
DÃ¼zeltilmiÅŸ R-kare ile R-kare oldukÃ§a birbirine yakÄ±n Ã§Ä±kmÄ±ÅŸ, model ve iÃ§indeki baÄŸÄ±msÄ±z deÄŸiÅŸkenler iyi bir ÅŸekilde SatÄ±ÅŸ deÄŸiÅŸkeninin varyansÄ±nÄ±n **%87.5**si nÄ± aÃ§Ä±klamÄ±ÅŸtÄ±r.

### Model VarsayÄ±mlarÄ±
#### Model GeÃ§erliliÄŸi F Hipotez Testi  
*\textcolor{red}{Ho : BaÄŸÄ±mlÄ± deÄŸiÅŸken ve baÄŸÄ±msÄ±z deÄŸiÅŸkenler arasÄ±nda doÄŸrusal bir iliÅŸki bulunmamaktadÄ±r.}*  
*\textcolor{red}{Ha : BaÄŸÄ±mlÄ± deÄŸiÅŸken ile en az bir baÄŸÄ±msÄ±z deÄŸiÅŸken arasÄ±nda doÄŸrusal bir iliÅŸki bulunmaktadÄ±r.}*  

- *Uygun Durum* : Ha: p_value < 0.05  
F istatistik deÄŸeri 474.3 payda 9 ve paydada 2913 Serbestlik derecesiyle 0.05 Ã¶nem dÃ¼zeyinde Ho reddedilmiÅŸtir ve model anlamlÄ± Ã§Ä±kmÄ±ÅŸtÄ±r ve baÄŸÄ±mlÄ± deÄŸiÅŸken ile en az bir baÄŸÄ±msÄ±z deÄŸiÅŸken arasÄ±nda doÄŸrusal bir iliÅŸki bulunmaktadÄ±r.  

#### Model KatsayÄ±larÄ±nÄ±n AnlamlÄ±lÄ±ÄŸÄ±na Ä°liÅŸkin Hipotez Testi
*\textcolor{red}{Ho : katsayÄ± 0'dan Ã¶nemli Ã¶lÃ§Ã¼de farklÄ± deÄŸildir.}*  
*\textcolor{red}{Ha : katsayÄ± 0'dan Ã¶nemli Ã¶lÃ§Ã¼de farklÄ±dÄ±r.}*  

- *Uygun Durum* : Ha: p_value < 0.05  
1. `SexM` katsayÄ±sÄ±nda 0.05 Ã¶nem dÃ¼zeyinde anlamsÄ±z Ã§Ä±kmÄ±ÅŸtÄ±r ve *0'dan Ã¶nemli Ã¶lÃ§Ã¼de farklÄ±dÄ±r* varsayÄ±mÄ± reddedilmiÅŸtir.
2. DiÄŸer deÄŸiÅŸkenlerin katsayÄ±larÄ± %95 gÃ¼venle anlamlÄ±dÄ±r

### StandarlaÅŸtÄ±rÄ±lmÄ±ÅŸ artÄ±klar  
ArtÄ±klarÄ±n yayÄ±ldÄ±ÄŸÄ±nÄ±n bir Ã¶lÃ§Ã¼sÃ¼ olan Residual standard error, modelin tahmin ettiÄŸi deÄŸerlerden gÃ¶zlemlenen Rings deÄŸerlerinin ortalama sapmasÄ±nÄ±, tane train verisinden 2913 serbestlik derecesiyle iyi bir miktar olarak 0.2026 gÃ¶stermektedir, ayrÄ±ca artÄ±klar `-1.39` ve `0.80` arasÄ±nda deÄŸiÅŸmektedirler.


- VIF deÄŸerleri incelendiÄŸinde daha Ã¶nce aynÄ± konseptten boy ve aÄŸÄ±rlÄ±k olarak veri tanÄ±tÄ±mÄ±nda ve korelasyon analizinde \textcolor{red}{Length, Diameter ve Height deÄŸiÅŸkenleri} bir birleri ile ve \textcolor{red}{Whole.weight, Shucked.weight, Viscera.weight ve Shell.weight deÄŸiÅŸkenleri} bir birleri ile iliÅŸkili olacaklarÄ±nÄ± vÄ±f (full model)de de bu **Multicollinearity** sorununu saptadÄ±k.
- korelasyon matrisinden ilerleyerek diÄŸer baÄŸÄ±msÄ±z deÄŸiÅŸkenlerle en az ve baÄŸÄ±mlÄ± deÄŸiÅŸkenle de en Ã§ok iliÅŸkisi olan deÄŸiÅŸkenleri son modele koymaya karar verdik.
- anlamsÄ±z deÄŸiÅŸkeni modelden Ã§Ä±karttÄ±k.

```{r echo=FALSE}
LR <- lm(log(Rings) ~  Height + Shucked.weight + Shell.weight,data = train)
a <- summary(LR)
a$call
paste (round(a$adj.r.squared,3), "Adjusted R squared")

```
Rings in varyansÄ±nÄ±n aÃ§Ä±klanabileceÄŸi Ã§ok da full model ile fark aÃ§mamÄ±ÅŸtÄ±r.

### VIF 

```{r echo=FALSE}
vif(LR)
```

*\textcolor{red}{GVIF < 5 veya 10 gereksinimi saÄŸlanmÄ±ÅŸtÄ±r ve Ã§oklu baÄŸlantÄ±lÄ±k problemi yoktur.}*

### VarsayÄ±mlar
#### HatalarÄ±n NormalliÄŸi

*\textcolor{red}{Ho: Hatalar Normal daÄŸÄ±lmaktadÄ±r.}*
*\textcolor{red}{Ha: Hatalar Normal daÄŸÄ±lmamaktadÄ±r.}*

**Shapiro Wilk Testi**  
- *Uygun Durum* Ho: p_value > 0.05
```{r echo=FALSE}
shapiro.test(LR$residuals)
```
Hatalar p_value: < 2.2e-16 olarak beklendiÄŸi gibi **logaritmik baÄŸÄ±mlÄ± deÄŸiÅŸken** normal daÄŸÄ±lmamaktadÄ±r.
- AykÄ±rÄ± deÄŸerler Ã§Ä±karÄ±lsada, scale ve bir Ã§ok dÃ¶nÃ¼ÅŸÃ¼m yapÄ±lsa da baÄŸÄ±mlÄ± deÄŸiÅŸkenin olaÄŸan Ã¼stÃ¼ normal daÄŸÄ±lmamasÄ± bu varsayÄ±mÄ± bozmaktadÄ±r.

#### HatalarÄ±n Sabit ve Homojen VaryanslÄ±lÄ±ÄŸÄ±

*\textcolor{red}{Ho: Hatalar Sabit VaryanslÄ±dÄ±r.}*
*\textcolor{red}{Ha: Hatalar Sabit VaryanslÄ± deÄŸildir.}*

**Breusch-Pagan Testi**
- *Uygun Durum* Ho: p_value > 0.05

```{r echo=FALSE}
bptest(log(Rings) ~ Height + Shucked.weight + Shell.weight, data=train)
```
Hatalar p_value: < 2.2e-16 olarak beklendiÄŸi gibi sabit ve homojen varyanslÄ± deÄŸildir.


\begin{center}\textcolor{blue}{DoÄŸrusal Regresyon modelinde Hedef deÄŸiÅŸkeninin varyansÄ±nÄ±n aÃ§Ä±klanmasÄ± dÃ¶nÃ¼ÅŸÃ¼mle bile 0.60 gibi az olmasÄ± ve Normal daÄŸÄ±lmamasÄ± dolayÄ±sÄ±yla da ArtÄ±klarÄ±n da Normal daÄŸÄ±lmamasÄ± bu veri seti iÃ§in yetersiz kaldÄ±ÄŸÄ±nÄ±n kanÄ±tÄ±dÄ±r ve herhangi bir tahmin ve devamÄ±nda Ã¶lÃ§Ã¼m metriklerinin hesaplanmasÄ± yanlÄ±ÅŸ olacaÄŸÄ± iÃ§in bu algoritma ile devam edilmeyecek.}\end{center}


## Regresyon AÄŸaÃ§larÄ±

```{r echo=FALSE}
set.seed(191)
treeRings <- tree(Rings~., data = train)
summary(treeRings)

```
- AÄŸaÃ§ta Shell.weight ve Shucked.weight deÄŸiÅŸkenlerinin verileri tahmine doÄŸru yÃ¶nelteceÄŸi saptanmÄ±ÅŸtÄ±r.
- BÃ¼tÃ¼n fit miktarlarÄ±nÄ±n gerÃ§ek miktarlardan sapmasÄ± 15900 bÃ¶lÃ¼ serbestlik derecesi 2914 ten artÄ±klarÄ±n ortalama sapmasÄ± 5.487 Ã§Ä±kmÄ±ÅŸtÄ±r.

```{r echo=FALSE, out.height="50%",out.width="70%"}

plot(treeRings)
text(treeRings, pretty = 0,
     cex=0.7, col = "blue",
     pos= 3,
     offset= 0.5)
```
- BeklediÄŸimiz gibi Shell.weight en Ã¶nemli verileri ayÄ±rt eden dÃ¼ÄŸÃ¼m yani kÃ¶k dÃ¼ÄŸÃ¼m Ã§Ä±kmÄ±ÅŸtÄ±r.
DÃ¼ÄŸÃ¼mlerde deÄŸiÅŸkene gelen gÃ¶zlem birimleri dÃ¼ÄŸÃ¼mde belirtilen miktarlardan az olan veri sol tarafa(**Left Branch**) ayÄ±rtÄ±ldÄ±ÄŸÄ±nÄ± gÃ¶rÃ¼yoruz.
- Terminal dÃ¼ÄŸÃ¼mlerde Ring in hangi aÄŸaÃ§ dalÄ±nda hangi deÄŸerler tahmin edildiÄŸini gÃ¶rmekteyiz.

### train Hata karelerinin ortalama kare kÃ¶kÃ¼
```{r echo=FALSE}
treeRings.pred <- predict(treeRings, train)

RMSE(treeRings.pred, train$Rings)
```

### test Hata karelerinin ortalama kare kÃ¶kÃ¼

```{r echo=FALSE}
treeRings.predtest <- predict(treeRings, test)

RMSE(treeRings.predtest, test$Rings)

```

### rpart paketi ile
bu paketin Ã¶zelliÄŸi cross validationÄ±nÄ± da kendisinin yapÄ±p en az hatanÄ±n olduÄŸu budanmÄ±ÅŸ aÄŸacÄ± otomatik olarak oluÅŸturmasÄ±dÄ±r, ama model karmaÅŸÄ±klÄ±ÄŸÄ±na dikkate almaz. O yÃ¼zden train ve test hatasÄ± hesaplanmamÄ±ÅŸtÄ±r.

```{r echo=FALSE}
treeRings2 <- rpart(Rings ~ ., data=train)
treeRings2$variable.importance
```

```{r echo=FALSE, out.height="50%",out.width="50%"}
par(xpd = TRUE)
rpart.plot(treeRings2)
```
deÄŸiÅŸkenlerin Ã¶nemi sÄ±ralandÄ±ÄŸÄ±nda en Ã¶nemli deÄŸiÅŸken Shell.weight olarak dikkat Ã§ekiyor.

aÄŸacÄ± incelediÄŸimizde kÃ¶k dÃ¼ÄŸÃ¼m olarak yine Shell.weight olmasÄ± dikkat Ã§ekiyor
toplam 9 adet terminal node bulunuyor. her bir atamayÄ± farklÄ± renklere ayÄ±rararak gÃ¶stermiÅŸ. renklerin tonu ise iÃ§erdiÄŸi gÃ¶zlem miktarÄ±nÄ± iÅŸaret ediyor.
Ã–rneÄŸin en aÃ§Ä±k renkle gÃ¶sterilen soldan ikinci terminal node gÃ¶zlemlerin %23 Ã¼ bu node da Ring miktarÄ± 8.3 olarak tahmin edilmiÅŸtir.

### BUDAMA
```{r echo=FALSE}
cv_tree <- cv.tree(treeRings)
plot(cv_tree$size,cv_tree$dev,type='b')
```
en uygun aÄŸaÃ§ sayÄ±sÄ± 5 olmaktadÄ±r ondan sonra tahmin sapmasÄ±nda hafif azalÄ±ÅŸ var.
```{r echo=FALSE, out.height="50%",out.width="50%"}
prune_tree=prune.tree(treeRings,best=5)
summary(prune_tree)
plot(prune_tree)
text(prune_tree, pretty = 0,
     cex=0.7, col = "blue",
     pos= 3,
     offset= 0.5)
partition.tree(prune_tree)
```
mean deviance full aÄŸaca gÃ¶re biraz artmÄ±ÅŸ ama karmaÅŸÄ±klÄ±k azalmÄ±ÅŸ ve Ã§Ä±ktÄ±lar tree plot ve kÄ±smi aÄŸaÃ§ plotÄ±ndan verilerin daÄŸÄ±lÄ±m yoÄŸunluÄŸu ve tahmin deÄŸerlerine iliÅŸkin daha yorumlanabilir ÅŸekle gelmiÅŸtir.

```{r echo=FALSE}
prune_tree.pred <- predict(prune_tree, train)

RMSE(prune_tree.pred, train$Rings)
```
train hata karelerinin ortalama kare kÃ¶kÃ¼
```{r echo=FALSE}
prune_tree.predtest <- predict(prune_tree, test)

RMSE(prune_tree.predtest, test$Rings)
```
test hata karelerinin ortalama kare kÃ¶kÃ¼

## 3 - Bagging Regresyon


```{r echo=FALSE, out.height="50%",out.width="60%"}
set.seed(191)
bag_reg<-randomForest(Rings~.,data=train,mtry=8,importance=TRUE)
bag_reg.pred<-predict(bag_reg,newdata=test)
RMSE(bag_reg.pred, test$Rings)

bag_reg$importance
varImpPlot(bag_reg)
```
Shell.weÄ±ght ve Shucked.weight burada da en Ã¶nemli deÄŸiÅŸkenler olduklarÄ± gÃ¶sterilmiÅŸtir.


## 4 - RANDOM FOREST

```{r echo=FALSE, out.height="50%",out.width="60%"}
set.seed(191)
RF_R<-randomForest(Rings~.,data=train,mtry=3,importance=TRUE)
RF_R_pred <-predict(RF_R,newdata=test)
plot(RF_R_pred,test$Rings) 
RMSE(RF_R_pred, test$Rings)
RF_R$importance
varImpPlot(RF_R)

```


Shell.weÄ±ght ve Shucked.weight burada da Ã¶nemli deÄŸiÅŸkenler olduklarÄ±yla birlikte Sex ve Whole.weÄ±ght deÄŸiÅŸkenlerin en Ã¶nemli olduklarÄ± dikkat Ã§ekiyor.

## 5 - Test verisi Ã¼zerinde performans karÅŸÄ±laÅŸtÄ±rmaasÄ±

- **Random** Forest 2.161193 rmse, bagging 2.199719 rmse, regresyon agaci 2.571849 ve varsayimlarÄ± saÄŸlanamayan doÄŸrusal regresyon yÃ¶ntemleri sÄ±rasÄ±yla budanmÄ±ÅŸ modelleri ile en iyi test hatalarÄ±nÄ± vermektedirler.

# B - SINIFLANDIRMA

YanÄ±t deÄŸiÅŸkenini Sex ="Infant" baz alarak en uygun eÅŸik deÄŸer Rings ve Sex="Infant" deÄŸiÅŸkenlerinin Rings in YoÄŸunluÄŸunu gÃ¶sterecek ÅŸekilde violon plotÄ± ile gÃ¶zlemlediÄŸimiz Rings in yÃ¼ksek deÄŸerlerine 1 ve dÃ¼ÅŸÃ¼k deÄŸerlerine 0 diyerek 4177 gÃ¶zlem olduÄŸuna raÄŸmen Ã§ok da fazla outlier i barÄ±ndÄ±rmadÄ±ÄŸÄ±nÄ± boxplotlada da gÃ¶rdÃ¼mÃ¼z iÃ§in istatistik metriklerinden mean veya median Ã§ok fazla farklÄ± olduklarÄ±nÄ± dÃ¼ÅŸÃ¼nmediÄŸim iÃ§in her iki durum iÃ§in eÅŸik deÄŸeri hesaplanmÄ±ÅŸtÄ±r.
```{r echo=FALSE}
ggplot(df[df$Sex == "I", ], aes(x = Sex, y = Rings)) +
  geom_violin(fill = "lightblue", color = "blue", alpha = 0.5) +
  labs(title = "Comparison of Rings for Infant", y = "Rings") +
  theme_minimal()
```

```{r echo=FALSE}
threshold_value <- mean(df$Rings[df$Sex == "I"])
threshold_value <- median(df$Rings[df$Sex == "I"])
```
median la hesaplanan eÅŸik deÄŸer 8 ve mean le hesaplanan 7.89 olmuÅŸtur. Rings 8 ve 8 den bÃ¼yÃ¼k deÄŸerler iÃ§in 1 ve 8 den kÃ¼Ã§Ã¼k deÄŸerler iÃ§in 0 alacak ÅŸekilde kodlanacaktÄ±r
```{r echo=FALSE}
df$Rings <- ifelse(df$Sex == "I" & df$Rings < threshold_value, 0, 1)
df$Rings <- as.factor(df$Rings)

train$Rings <- ifelse(train$Sex == "I" & train$Rings < threshold_value, 0, 1)
train$Rings <- as.factor(train$Rings)

test$Rings <- ifelse(test$Sex == "I" & test$Rings < threshold_value, 0, 1)
test$Rings <- as.factor(test$Rings)
```



## 6 - SINIFLANDIRMA AÄACI
```{r echo=FALSE, out.height="50%",out.width="60%"}
set.seed(191)
treeRings <- tree(Rings~., train)
summary(treeRings)
plot(treeRings)
text(treeRings, pretty = 0,
     cex=0.8, col = "blue",
     pos= 2,
     offset= 0.5)
```
AÄŸaÃ§ Sex, Shell.weight ve Diameter deÄŸiÅŸkenleri ve Toplam 5 terminal node ile oluÅŸmuÅŸtur.
KÃ¶k dÃ¼ÄŸÃ¼m olarak Sex saptanmÄ±ÅŸtÄ±r.
Residual mean deviance 0.2253 olarak dikkat Ã§ekiyor.
iÃ§ dÃ¼ÄŸÃ¼mlerde saÄŸ tarafta Sex Infant kategorisinde olmayan verilerin Rings deÄŸeri 1 ve sol tarafta Shell.weight ve Diameter nodelarÄ±nda deÄŸiÅŸiklik olmamasÄ± ve buralarda dallanmanÄ±n anlamÄ± olmadÄ±ÄŸÄ± iÃ§in aÄŸaÃ§ budamasÄ± ÅŸarttÄ±r.

### Tahminler
train iÃ§in
```{r echo=FALSE}
treeRings.pred <- predict(treeRings,train,type = "class")
a <- caret::confusionMatrix(treeRings.pred,train$Rings)
a$overall[1]
```
test iÃ§in
```{r echo=FALSE}
treeRings.predtest <- predict(treeRings, test,type = "class")
a <- caret::confusionMatrix(treeRings.predtest,test$Rings)
a$overall[1]
```

Cross Validation le uygun aÄŸac siza karar vermek
```{r echo=FALSE}
set.seed(191)
cv.treeRings <- cv.tree(treeRings,FUN = prune.misclass)
plot(cv.treeRings$size ,cv.treeRings$dev ,type="b")
```
Her iki grafik de incelendiÄŸinde size'Ä±n 3 olduÄŸu noktada deviance'de belirgin azalmalar dikkat Ã§ekmekte ve 4 veya 5 dÃ¼ÄŸÃ¼me ihtiyaÃ§ yoktur.

### Budama 

```{r echo=FALSE}
prune.treeRings <- prune.misclass (treeRings,best=3)
summary(prune.treeRings)
plot(prune.treeRings)
text(prune.treeRings, pretty = 0,
     cex=0.8, col = "blue",
     pos= 2,
     offset= 0.5)
```
Budama sonrasÄ± residual mean deviance'Ä±nÄ±n 0.265 olarak saptanmÄ±ÅŸ. Biraz artÄ±ÅŸ gÃ¶stermiÅŸ gÃ¶rÃ¼nÃ¼yor.
Error rate ise 0.047 deÄŸerini almÄ±ÅŸ. Misclassification error rate deÄŸiÅŸmemiÅŸtir.
YalnÄ±zca 3 terminal node olduÄŸu iÃ§in Ã§ok verimli bir aÄŸaÃ§ olduÄŸu sÃ¶ylenemez. 
AÄŸaÃ§ yalnÄ±zca Sex ve Shell.weight deÄŸiÅŸkenleri kullanÄ±larak oluÅŸturulmuÅŸ.

### BudanmÄ±ÅŸ - Tahminler
train iÃ§in
```{r}
prunedtree.pred <- predict(prune.treeRings, train, type = "class")
a <- caret::confusionMatrix(prunedtree.pred, train$Rings)
a$overall[1]
```

test iÃ§in
```{r}
prunedtree.predtest <- predict(prune.treeRings, test, type = "class")
a <- caret::confusionMatrix(prunedtree.predtest, test$Rings)
a$overall[1]
```
**rpart ile**
```{r}
treeRings2 <- rpart(Rings ~., data = train, method = "class")
treeRings2$variable.importance
rpart.plot::rpart.plot(treeRings2)
```
- burada da en Ã¶nemli deÄŸiÅŸken Shell.weight olmuÅŸtur.
Toplamda 3 terminal node bulunmakta verilerin daÄŸÄ±lÄ±m yoÄŸunluÄŸunun yÃ¼zdelikleri gÃ¶sterilmiÅŸ ve tahmin edilen miktar 0 veya 1 olarak sÄ±nÄ±flandÄ±rÄ±lmÄ±ÅŸtÄ±r. 

- aynÄ± manuel budama yaptÄ±ÄŸÄ±mÄ±z aÄŸaÃ§ Ã§Ä±ktÄ±ÄŸÄ± iÃ§in Accuracy deÄŸerinin Ã§ok az fark edebileceÄŸinden tahmin hata metriklerini hesaplamaya gerek duyulmamÄ±ÅŸtÄ±r.


## 7 - Bagging

```{r}
set.seed(191)
bag <- randomForest(Rings~., data = train, mtry = 8, importance=TRUE)

varImpPlot(bag)
```
1. deÄŸiÅŸkenlerin Ã¶nemlerini iÅŸaret eden grafik incelendiÄŸinde mean decrease accuracy deÄŸerine gÃ¶re Ã¶nemli deÄŸiÅŸkenler: Sex, Shell.weight,, Lenght, Diameter, Viscera.weight
2. dÃ¼ÄŸÃ¼m saflÄ±ÄŸÄ±nÄ± iÅŸaret eden gini deÄŸerine gÃ¶re Ã¶nemli deÄŸiÅŸkenler: Shell.weight, Sex, Viscera.weight, Shucked.weight, Whole.weight ve Lenght olmuslardir.

### Tahminler
train icin
```{r}
bagging_pred <- predict(bag, train, type = "class")
a <- caret::confusionMatrix(bagging_pred, train$Rings)
a$overall[1]
```
test icin
```{r}
bagging_predtest <- predict(bag, test, type = "class")
a <- caret::confusionMatrix(bagging_predtest, test$Rings)
a$overall[1]
```

### ipred paketi ile

- Modele kaÃ§ iterasyonun dahil edileceÄŸini kontrol etmek iÃ§in nbagg kullanÄ±lÄ±r 
- coob = TRUE OOB hata oranÄ±nÄ± kullanmayÄ± gÃ¶stermektedir. 
- tr control argÃ¼mani ile 10-fold cross validation fonksiyonun iÃ§inde uygulanÄ±r
```{r}
set.seed(191)
bag2 <-bagging(
  formula = Rings~.,
  data = train,
  nbagg = 500,
  coob=TRUE,
  method="treebag",
  trControl = trainControl(method = "cv", number = 10)
)
bag2$err

```
OOB Missclassification error rate 0.05987 olarak saptanmÄ±ÅŸtÄ±r.

```{r}
VI <- data.frame(var=names(train[,-9]), imp=varImp(bag2))

VI_plot <- VI[order(VI$Overall, decreasing=F),]

par(mar = c(5, 7, 2, 2))  # c(bottom, left, top, right)
barplot(VI_plot$Overall,
        names.arg=rownames(VI_plot),
        horiz=T,
        col="goldenrod1",
        xlab="Variable Importance",
        las = 2)
```

DeÄŸiÅŸkenlerin Ã¶nemini ifade eden grafiÄŸi incelediÄŸimizde bir Ã¶nceki paketten daha farklÄ± bir grafikle karÅŸÄ±laÅŸÄ±lmÄ±ÅŸtÄ±r.
shell.weight ve sex deÄŸiÅŸkenleri diÄŸer pakette en Ã¶nemli deÄŸiÅŸkenler olarak gÃ¶rÃ¼nÃ¼rken bu sefer shell.weight ve Whole.weight deÄŸiÅŸkenlerinin daha Ã¶nemli olduÄŸu fark edilmiÅŸtir.

####Tahminler
train icin
```{r}
bagging_pred2 <- predict(bag2 ,train ,type="class")
a<- caret::confusionMatrix(bagging_pred2, train$Rings)
a$overall[1]
```
test icin
```{r}
bagging_predtest2 <- predict(bag2 ,test ,type="class")
a <- caret::confusionMatrix(bagging_predtest2, test$Rings)
a$overall[1]
```

## 8 - RANDOM FOREST CLASSIFICATION
```{r}
set.seed(191)
RF.C <- randomForest(Rings~., data = train, mtry=3, importance=TRUE)
RF.C$confusion
RF.C
```
SÄ±fÄ±rÄ±ncÄ± sÄ±nÄ±f iÃ§in hata 0.16, birinci sÄ±nÄ±f iÃ§in ise 0.035 olarak saptanmÄ±ÅŸ. Toplam 159 gÃ¶zlem yanlÄ±ÅŸ olarak sÄ±nÄ±flandÄ±rÄ±lmÄ±ÅŸ.

OOB estimate error rate ise %5.44 Ã§Ä±kmÄ±ÅŸ. Bunun az olduÄŸu sÃ¶ylenilebilir.
her bir ayrÄ±ÅŸmada 3 deÄŸiÅŸken denenmiÅŸ.
Toplam 500 aÄŸaÃ§ kurulmuÅŸ.
```{r}
varImpPlot(RF.C)
```
DeÄŸiÅŸkenlerin Ã¶nemlerine bakÄ±ldÄ±ÄŸÄ±nda;

- Mean decrease accuracy incelendiÄŸinde en Ã§ok Sex ve Shell.weight sÄ±ralamasÄ± dikkat Ã§ekmekte.
- Gini deÄŸerlerine bakÄ±ldÄ±ÄŸÄ±nda ise Shell.weight ve Sex sÄ±ralamasÄ± dikkat Ã§ekiyor

- Baggin ile oldukÃ§a paralel olduÄŸunu sÃ¶ylemek yanlÄ±ÅŸ olmaz.
### Tahminler
train icin
```{r}
RF.C_pred.train <- predict(RF.C, train, type = "class")
a <- caret::confusionMatrix(RF.C_pred.train, train$Rings)
a$overall[1]
```
test icin
```{r}
RF.C_pred.test <- predict(RF.C, test, type = "class")
a <- caret::confusionMatrix(RF.C_pred.test, test$Rings)
a$overall[1]
```
### Grid Search ile
Grid search'te aÄŸaÃ§ sayÄ±sÄ± aralÄ±ÄŸÄ±na karar vermek iÃ§in grafik Ã§izdirilmiÅŸtir.

```{r}
plot(RF.C)

hyper_grid <- expand.grid(
  mtry = c(2, 3, 4, 5),
  nodesize = c(1, 3, 4, 5, 10), 
  numtrees = c(200, 220,300,330,500),
  rmse = NA                                               
)

for (i in 1:nrow(hyper_grid)) {
  fit <- randomForest(Rings~. ,
                      data=train, 
                      mtry=hyper_grid$mtry[i],
                      nodesize = hyper_grid$nodesize[i],
                      ntree = hyper_grid$numtrees[i],
                      importance=TRUE)
  hyper_grid$rmse[i] <- mean(fit$confusion[,3])
}


hyper_grid %>%
  arrange(rmse) %>%
  head(10)
```
BÃ¶ylelikle en iyi parametrelerle kurulacak model aÅŸaÄŸÄ±daki gibi olmalÄ±dÄ±r.
```{r}
RF.C2 <- randomForest(Rings~., data = train, mtry= 4, importance= TRUE, nodesize=10,ntree= 220)
RF.C2$confusion

RF.C2
```
SÄ±fÄ±rÄ±ncÄ± sÄ±nÄ±f iÃ§in hata 0.15, birinci sÄ±nÄ±f iÃ§in ise 0.034 olarak saptanmÄ±ÅŸ. Toplam 153 gÃ¶zlem yanlÄ±ÅŸ olarak sÄ±nÄ±flandÄ±rÄ±lmÄ±ÅŸ.
ve bir Ã¶ncekine gÃ¶re iyileÅŸme olmuÅŸtur.
OOB estimate error rate ise %5.23 Ã§Ä±kmÄ±ÅŸ. Bunun az olduÄŸu sÃ¶ylenilebilir.
her bir ayrÄ±ÅŸmada 4 deÄŸiÅŸken denenmiÅŸ.
Toplam 220 aÄŸaÃ§ kurulmuÅŸ.

```{r}
RF.C2$importance
```

```{r}
varImpPlot(RF.C2)
```
aynÄ± bir Ã¶nceki gibi deÄŸiÅŸkenlerin Ã¶nem sÄ±rasÄ±
#### Tahminler
train icin
```{r echo=FALSE}
RF.C2_pred.train <- predict(RF.C2, train, type = "class")
a <- caret::confusionMatrix(RF.C2_pred.train, train$Rings)
a$overall[1]
```
test icin
```{r echo=FALSE}
RF.C2_pred.test <- predict(RF.C2, test, type = "class")
a <- caret::confusionMatrix(RF.C2_pred.test, test$Rings)
a$overall[1]
```

## 9 - Logistic Regresyon

Burada da aynÄ± linear regresyon gibi vif a duyarlÄ± algoritma olduÄŸu iÃ§in anlamsÄ±z ve Ã§oklu baÄŸlantÄ±lÄ±k problemi yaradan deÄŸiÅŸkenleri modelden kaldÄ±rdÄ±k ve son model aÅŸaÄŸÄ±daki gibidir.
```{r echo=FALSE}
logmodel <- glm(Rings ~ Height + Shucked.weight + Shell.weight,data = train, family=binomial)
summary(logmodel)
paste (exp(21.9160),"kat odds oraninda degisiklik olur eger Height degiskeninde 1 birimlik artÄ±s olursa.")
paste (exp(-4.6829),"kat odds oraninda degisiklik olur eger Shucked.weight degiskeninde 1 birimlik artÄ±s olursa.")
paste (exp(31.6321),"kat odds oraninda degisiklik olur eger Shell.weight degiskeninde 1 birimlik artÄ±s olursa.")
```

- modelin anlamlÄ±lÄ±ÄŸÄ±

ğ» 0 : ğ›½ 1 = ğ›½ 2 = â‹¯ = ğ›½ ğ‘˜ = 0
ğ» 1 : En azÄ±ndan bir ğ›½ ğ‘— â‰  0
G= Null deviance-Residual Deviance
```{r}
1-pchisq(2480.0 - 1113.5, 2922-2919) 
```

Bu p-deÄŸeri .05'ten kÃ¼Ã§Ã¼k olduÄŸu iÃ§in sÄ±fÄ±r hipotezini reddebiliriz. 
BaÅŸka bir deyiÅŸle, baÄŸÄ±msÄ±z deÄŸiÅŸkenlerin baÄŸÄ±mlÄ± deÄŸiÅŸkeni aÃ§Ä±klamada etkili olduÄŸunu sÃ¶yleyebilecek yeterli istatistiksel kanÄ±tÄ±mÄ±z bulunmaktadÄ±r. 

**Vif**
```{r echo=FALSE}
vif(logmodel)
outlierTest(logmodel)
```
Bonferroni'ye gÃ¶re herhangi bir uÃ§ deÄŸer bulunmamakta.
```{r echo=FALSE}
confint.default(logmodel)
```

Î² katsayÄ±sÄ±na ait gÃ¼ven aralÄ±ÄŸÄ± sfÄ±r deÄŸerini iÃ§ermediÄŸi iÃ§in Ho hipotezi red edilerek aÅŸaÄŸÄ±daki katsayÄ±larÄ±n istatistiksel olarak anlamlÄ± olduÄŸuna karar verilmiÅŸtir.
Height, Shucked.weight, Shell.weight ve Whole.weight

Î² katsayÄ±sÄ±na ait gÃ¼ven aralÄ±ÄŸÄ± sfÄ±r deÄŸerini iÃ§erdiÄŸi iÃ§in Ho hipotezi red edilemeyerek diger katsayÄ±larÄ±n istatistiksel olarak anlamlÄ± olmadÄ±ÄŸÄ±na karar verilmiÅŸtir.


odds deÄŸeri  iÃ§in gÃ¼ven aralÄ±ÄŸÄ±
```{r echo=FALSE}
odds.confint <- exp(confint.default(logmodel))
odds.confint
```
Verininin logistic regresyon modeline fit edip edemediÄŸini kontrol etmek
iÃ§in Hosmer-Lemeshow testini uyguluyorum.
```{r echo=FALSE}
library(performance)
performance_hosmer(logmodel, n_bins = 10)
```

### Tahminler

train icin
```{r echo=FALSE}
logmodel_pred = predict(logmodel, newdata=train)
logmodel_pred <- ifelse(logmodel_pred > 0.5,1,0)
a <- caret::confusionMatrix(as.factor(logmodel_pred), train$Rings)
a$overall[1]
```
test icin
```{r echo=FALSE}
logmodel_predtest = predict(logmodel, newdata=test)
logmodel_predtest <- ifelse(logmodel_predtest > 0.5,1,0)
a <- caret::confusionMatrix(as.factor(logmodel_predtest), test$Rings)
a$overall[1]
```

## 10-LDA
```{r echo=FALSE}
train_lda <- train[,c(2,3,4,5,6,7,8,9)]
test_lda <- test[,c(2,3,4,5,6,7,8,9)]

```

```{r echo=FALSE}
model_lda<-lda(Rings~.,data=train_lda)
model_lda
```
Linear discriminant analysis modelinin Ã§Ä±ktÄ±sÄ± incelendiÄŸinde:
YalnÄ±zca bir adet doÄŸrusal ayrÄ±m olduÄŸu saptanmÄ±ÅŸtÄ±r.
Oranlar birbirine kabul edilebilir uzakliktadir.

### Tahminler

train icin
```{r echo=FALSE}
model_lda.pred <-predict(model_lda,train_lda)
a <- caret::confusionMatrix(model_lda.pred$class, train_lda$Rings)
a$overall[1]
```
test icin
```{r echo=FALSE}
model_lda.predtest <-predict(model_lda,test_lda)
a <- caret::confusionMatrix(model_lda.predtest$class, test_lda$Rings)
a$overall[1]
```

```{r echo=FALSE}
hist_lda1<-ldahist(data=model_lda.pred$x[,1],g=train_lda$Rings) 
```
Birinci fonksiyona gÃ¶re nasÄ±l ayrÄ±lmasÄ± gerektiÄŸini gÃ¶steren karÅŸÄ±laÅŸtÄ±rmalÄ± histogramlar incelendiÄŸinde:
- YaklaÅŸÄ±k olarak -2 deÄŸeriyle 0 deÄŸerleri arasÄ±nda Ã¶rtÃ¼ÅŸme gÃ¶rÃ¼lmekte. 
- Bu olasÄ± yanlÄ±ÅŸ ayÄ±rmayÄ± gÃ¶steriyor olabilir.

### 11 - Quadratik Discriminant Analysis
```{r echo=FALSE}
set.seed(191)
train_indices <- sample(2, size=nrow(df), replace = TRUE, prob=c(0.7,0.3))
train_qda <- df[train_indices==1, ]
test_qda <- df[train_indices==2, ]

train_qda <- train_qda[,c(2,3,4,5,6,7,8,9)]
test_qda <- test_qda[,c(2,3,4,5,6,7,8,9)]

model_qda <- qda(Rings~., data=train_qda)
model_qda
```
BazÄ± deÄŸiÅŸkenlerin olasÄ±lÄ±klarÄ± arasÄ±ndaki farkÄ±n bu denli dÃ¼ÅŸÃ¼k olmasÄ± modelin gÃ¼venilirliÄŸini sorgulatmaktadÄ±r.

### Tahminler
train icin
```{r echo=FALSE}
model_qda.pred <- predict(model_qda ,train_qda)
a <- caret::confusionMatrix(model_qda.pred$class, train_qda$Rings)
a$overall[1]
```
test icin
```{r echo=FALSE}
model_qda.predtest <- predict(model_qda ,test_qda)
a <- caret::confusionMatrix(model_qda.predtest$class, test_qda$Rings)
a$overall[1]
```

```{r echo=FALSE}
dfmvn <- df[,c(2,3,4,5,6,7,8,9)]
sifir <- df[df$Rings==0,c(2,3,4,5,6,7,8,9)]
sifir <- sifir[,-8]

bir <- df[df$Rings==1, c(2,3,4,5,6,7,8,9)]
bir <- bir[,-8]


result <- mvn(data = dfmvn, subset = "Rings", mvnTest = "hz")
result$multivariateNormality
```
Henze - Zinkler normallik testine gÃ¶re 0.05 anlamlÄ±lÄ±k dÃ¼zeyinde Ho verilerin Ã§oklu normal daÄŸÄ±lÄ±mdan geldiÄŸi hipotezi reddedilebilir.

```{r echo=FALSE}
leveneTest(df$Length ~ df$Rings, df)

leveneTest(df$Diameter ~ df$Rings, df) 

leveneTest(df$Height ~ df$Rings, df) 

leveneTest(df$Shucked.weight ~ df$Rings, df) 

leveneTest(df$Shell.weight ~ df$Rings, df) 
```
Levene varyans homojenliÄŸi testine gÃ¶re 0.05 anlamlÄ±lÄ±k dÃ¼zeyinde Ho bÃ¼tÃ¼n deÄŸiÅŸkenler iÃ§in sÄ±nÄ±flara gÃ¶re varyanslarÄ±nÄ±n homojenliÄŸi olduÄŸu hipotezini reddedilemediÄŸi ni gÃ¶rÃ¼yoruz. Yani deÄŸiÅŸkenlerin hepsinin varyansÄ± homojendir.

```{r echo=FALSE}

library(heplots)
boxm <- heplots::boxM(df[, c(2,3,4,5,6,7,8)], df$Rings) 
boxm 

par(mar = c(6, 5, 5, 6)+ 1)
plot(boxm)
```
p-value 0.05'ten kÃ¼Ã§Ã¼k Ã§Ä±ktÄ±ÄŸÄ± iÃ§in 0.05 anlamlÄ±lÄ±k seviyesinde Ho baÄŸÄ±msÄ±z deÄŸiÅŸkenlerin kovaryans matrislerinin eÅŸit olduÄŸu varsayÄ±mÄ± reddedilebilir.


## 12

```{r include=FALSE}
predct <- prediction(as.numeric(as.vector(prunedtree.predtest)), test$Rings)

predbag <- prediction(as.numeric(as.vector(bagging_predtest2)), test$Rings)

predRF <- prediction(as.numeric(as.vector(RF.C2_pred.test)), test$Rings)

predlog <- prediction(as.numeric(as.vector(logmodel_predtest)), test$Rings)

predlda <- prediction(as.numeric(as.vector(model_lda.predtest$class)), test_lda$Rings)
predqda <- prediction(as.numeric(as.vector(model_qda.predtest$class)), test_qda$Rings)


```

### AUC DeÄŸerleri
```{r}
aucct <-ROCR::performance(predct, measure="auc")
paste(round(aucct@y.values[[1]],6), "CT AUC degeri")
aucbag <-ROCR::performance(predbag, measure="auc")
paste(round(aucbag@y.values[[1]],6), "Bagging AUC degeri")
aucRF <-ROCR::performance(predRF, measure="auc")
paste(round(aucRF@y.values[[1]],6), "RF AUC degeri")
auclog <-ROCR::performance(predlog, measure="auc")
paste(round(auclog@y.values[[1]],6), "Log AUC degeri")
auclda <-ROCR::performance(predlda, measure="auc")
paste(round(auclda@y.values[[1]],6), "LDA AUC degeri")
aucqda <-ROCR::performance(predqda, measure="auc")
paste(round(aucqda@y.values[[1]],6), "QDA AUC degeri")
```

### ROC eÄŸrisi
```{r echo=FALSE}
perfct <-ROCR:: performance( predct, "tpr", "fpr" )
perfbag <-ROCR:: performance(predbag, "tpr", "fpr")
perfrf <-ROCR:: performance(predRF, "tpr", "fpr")
perflr <-ROCR:: performance(predlog, "tpr", "fpr")
perflda <-ROCR:: performance(predlda, "tpr", "fpr")
perfqda <-ROCR:: performance(predqda, "tpr", "fpr")



plot(perfct, col = "firebrick3", lwd = 2, lty = 1)
plot(perfbag, add = TRUE, col = "aquamarine3", lwd = 2, lty =2)
plot(perfrf, add=T, col = "black", lwd = 2, lty = 6)
plot(perflda, add = TRUE, col = "lightpink3", lwd = 2, lty =4)
plot(perfqda,add=T, col = "burlywood3", lwd = 2, lty =3)
plot(perflr, add = TRUE, col = "dodgerblue3", lwd = 2, lty=5)
legend("bottomright", title = "Algoritma - AUC DeÄŸeri", legend= c("ct - 0.89", "bag - 0.899", "RF - 0.90", "lda - 0.75", "qda - 0.86", "log - 0.81"), col = c( "firebrick3", "aquamarine3", "black","lightpink3","burlywood3","dodgerblue3"), lty = c(1,2,6,4,3,5), lwd = 2)


```
\textcolor{blue}{AUC miktarÄ±nÄ±n artÄ±ÅŸÄ± Roc curve Ã§izgisinin altÄ±ndaki alanÄ±nÄ±n artmasÄ±yla iliÅŸkilidir.
**EN Ã‡ok alana sahip ve AUC deÄŸeri fazla olan algoritma Random Forest olmuÅŸtur**
En iyi algoritma olarak Random Forest e karar verilmiÅŸtir, test metrikleri incelendikten sonra kesin karar verilecektir}

## 13

### Tablo         
```{r echo=FALSE}
preds <- data.frame()
preds[1,1] <- "treeRings"
preds[2,1] <- "treeRings"
preds[1,2] <- "train"
preds[2,2] <- "test"
preds[1,3] <- 0.9524 
preds[2,3] <- 0.9314 
preds[1,4] <- 0.8866
preds[2,4] <- 0.8502
preds[1,5] <- 0.9641
preds[2,5] <- 0.9475

##############################

preds[3,1] <- "Bagging"
preds[4,1] <- "Bagging"
preds[3,2] <- "train"
preds[4,2] <- "test"
preds[3,3] <- 1.0000
preds[4,3] <- 0.9354
preds[3,4] <- 1.0000
preds[4,4] <- 0.8454
preds[3,5] <- 1.0000
preds[4,5] <- 0.9532


#################################

preds[5,1] <- "RanFor"
preds[6,1] <- "RanFor"
preds[5,2] <- "train"
preds[6,2] <- "test"
preds[5,3] <- 0.9839
preds[6,3] <- 0.9346
preds[5,4] <- 0.9615
preds[6,4] <- 0.8357
preds[5,5] <- 0.9879
preds[6,5] <- 0.9542

#################################

preds[7,1] <- "LogReg"
preds[8,1] <- "LogReg"
preds[7,2] <- "train"
preds[8,2] <- "test"
preds[7,3] <- 0.9138
preds[8,3] <- 0.8828
preds[7,4] <- 0.7823
preds[8,4] <- 0.7150
preds[7,5] <- 0.9371
preds[8,5] <- 0.9160

#################################

preds[9,1] <- "LDA"
preds[10,1] <- "LDA"
preds[9,2] <- "train"
preds[10,2] <- "test"
preds[9,3] <- 0.9011
preds[10,3] <- 0.8788
preds[9,4] <- 0.60544
preds[10,4] <- 0.57971
preds[9,5] <- 0.95367
preds[10,5] <- 0.93792

#################################

preds[11,1] <- "QDA"
preds[12,1] <- "QDA"
preds[11,2] <- "train"
preds[12,2] <- "test"
preds[11,3] <- 0.8579
preds[12,3] <- 0.8465
preds[11,4] <- 0.8886
preds[12,4] <- 0.8947
preds[11,5] <- 0.8522
preds[12,5] <- 0.8380

#################################

names(preds) <- c("Algoritma", "TT", "Accuracy_Rate", "Sensivity", "Specificity" )

preds

```
### ACCURACY & SENCITIVITY & SPECIFICITY
```{r echo=FALSE}
preds %>% 
  ggplot(aes(x= Accuracy_Rate, y= reorder(Algoritma, -Accuracy_Rate))) +
  geom_line(stat="identity") +
  geom_point(aes(color=TT), size=4) +
  theme(legend.position="top") +
  theme(panel.background = element_rect(fill="white"))+
  xlab("Accuracy Rate") +
  ylab("Algoritma")


preds %>% 
  ggplot(aes(x= Sensivity, y= reorder(Algoritma, -Sensivity))) +
  geom_line(stat="identity") +
  geom_point(aes(color=TT), size=3) +
  theme(legend.position="top") +
  theme(panel.background = element_rect(fill="white"))+
  xlab("Sensitivity") +
  ylab("Algoritma")


preds %>% 
  ggplot(aes(x= Specificity, y= reorder(Algoritma, -Specificity))) +
  geom_line(stat="identity") +
  geom_point(aes(color=TT), size=3) +
  theme(legend.position="top") +
  theme(panel.background = element_rect(fill="white"))+
  xlab("Specificity") +
  ylab("Algoritma")

```

- KÄ±rmÄ±zÄ± noktalar test setinin performanslarÄ±nÄ± gÃ¶sterdikleri iÃ§in Ã¶nem arzetmektedir.
- **Sirasiyla Random Forest, Bagging ve sÄ±nÄ±flandÄ±rma aÄŸaÃ§larÄ± en iyi algoritmalar olarak kabul edilir.**
\begin{center}\textcolor{red}{bu yÃ¼zden tablodan da anlaÅŸÄ±ldÄ±ÄŸÄ± gibi duyarlÄ±lÄ±k ve doÄŸruluk metriklerinde bagging Ã§ok az farkla iyi Ã§Ä±ktÄ±ÄŸÄ±na raÄŸmen Random Forest AUC deÄŸeri Bagging AUC deÄŸerinden fazla idi, buna ek Ã¶zgÃ¼llÃ¼k metriÄŸine gÃ¶re de Random Forest bir tÄ±k daha iyi sonuÃ§ vermektedir, dolayÄ±sÄ±yla En iyi algoritma Random Forest ve modelin bu algoritmada Grid Search ile budanmÄ±ÅŸ hali en iyi model dir.
En iyi Model RF.C2 <- randomForest(Rings~., data = train, mtry= 4, importance= TRUE, nodesize=10,ntree= 220) olarak karar verilmiÅŸtir.}\end{center}
\begin{center}\textcolor{blue}{ Regresyon yÃ¶ntemlerinin test hata metriklerini Rings deÄŸiÅŸkeni net bir ÅŸekilde kategorik olduÄŸu iÃ§in Random Forest gibi robust yÃ¶ntemler yanÄ± sÄ±ra incelemeye gerek duyulmamÄ±ÅŸtÄ±r.}\end{center}
